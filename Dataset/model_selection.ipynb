{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('E:\\Excelr-P269-Internship-Project-Group2-OIl-Price-Prediction-And-Forecasting-Using-Python\\Dataset\\IQR.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            Date      Price  Year\n",
      "5746  2023-07-17  74.150002  2023\n",
      "5747  2023-07-18  75.750000  2023\n",
      "5748  2023-07-19  75.349998  2023\n",
      "5749  2023-07-20  75.629997  2023\n",
      "5750  2023-07-21  77.070000  2023\n"
     ]
    }
   ],
   "source": [
    "df=pd.DataFrame(data)\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ADF Statistic: -13.994867\n",
      "p-value: 0.000000\n",
      "Critical Values:\n",
      "\t1%: -3.431\n",
      "\t5%: -2.862\n",
      "\t10%: -2.567\n",
      "The data is stationary\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import boxcox\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "data = data[['Price']]\n",
    "\n",
    "# Fill missing values using interpolation\n",
    "# Set the index to a DatetimeIndex\n",
    "data.index = pd.DatetimeIndex(data.index)\n",
    "\n",
    "# Fill missing values using interpolation\n",
    "data = data.interpolate(method='time')\n",
    "# Make the data stationary\n",
    "def make_stationary(data):\n",
    "    # Take the first difference of the data\n",
    "    data_diff = data.diff().dropna()\n",
    "    \n",
    "    # Check if the data is stationary using the Augmented Dickey-Fuller test\n",
    "    from statsmodels.tsa.stattools import adfuller\n",
    "    result = adfuller(data_diff)\n",
    "    print('ADF Statistic: %f' % result[0])\n",
    "    print('p-value: %f' % result[1])\n",
    "    print('Critical Values:')\n",
    "    for key, value in result[4].items():\n",
    "        print('\\t%s: %.3f' % (key, value))\n",
    "    \n",
    "    # If the p-value is less than 0.05, the data is stationary\n",
    "    if result[1] < 0.05:\n",
    "        print('The data is stationary')\n",
    "        return data_diff\n",
    "    else:\n",
    "        print('The data is not stationary')\n",
    "        return make_stationary(data_diff)\n",
    "\n",
    "data = make_stationary(data)\n",
    "\n",
    "# Data Transformation\n",
    "# Apply Box-Cox transformation\n",
    "data['Price'] = data['Price'] - data['Price'].min() + 1\n",
    "data['Price'], lam = boxcox(data['Price'])\n",
    "\n",
    "# Data Normalization\n",
    "# Normalize the data using MinMaxScaler\n",
    "scaler = MinMaxScaler()\n",
    "data['Price'] = scaler.fit_transform(data[['Price']])\n",
    "\n",
    "# Feature Engineering\n",
    "# Create lag features\n",
    "for i in range(1, 13):\n",
    "    data[f'lag_{i}'] = data['Price'].shift(i)\n",
    "\n",
    "# Create rolling window statistics\n",
    "data['rolling_mean'] = data['Price'].rolling(window=12).mean()\n",
    "data['rolling_std'] = data['Price'].rolling(window=12).std()\n",
    "\n",
    "# Train-Test Split\n",
    "# Split the data into training and test sets\n",
    "train_size = int(len(data) * 0.8)\n",
    "train, test = data[0:train_size], data[train_size:len(data)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'fbprophet'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mfbprophet\u001b[39;00m \u001b[39mimport\u001b[39;00m Prophet\n\u001b[0;32m      3\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m Sequential\n\u001b[0;32m      4\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mlayers\u001b[39;00m \u001b[39mimport\u001b[39;00m LSTM, Dense\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'fbprophet'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from fbprophet import Prophet\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "# Load the data\n",
    "data = pd.read_csv('data.csv', parse_dates=['Date'], index_col='Date')\n",
    "data = data[['Price']]\n",
    "\n",
    "# Prepare the data for Prophet\n",
    "prophet_data = data.reset_index()\n",
    "prophet_data.columns = ['ds', 'y']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_size = int(len(data) * 0.8)\n",
    "train, test = prophet_data[0:train_size], prophet_data[train_size:len(prophet_data)]\n",
    "\n",
    "# Fit the Prophet model\n",
    "prophet_model = Prophet()\n",
    "prophet_model.fit(train)\n",
    "\n",
    "# Make predictions using the Prophet model\n",
    "prophet_forecast = prophet_model.predict(test[['ds']])\n",
    "prophet_predictions = prophet_forecast['yhat'].values\n",
    "\n",
    "# Calculate the mean squared error of the Prophet model\n",
    "prophet_mse = mean_squared_error(test['y'], prophet_predictions)\n",
    "print(f'Prophet MSE: {prophet_mse}')\n",
    "\n",
    "# Prepare the data for LSTM\n",
    "lstm_data = data.values\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train, test = lstm_data[0:train_size], lstm_data[train_size:len(lstm_data)]\n",
    "\n",
    "# Define a function to create input-output pairs for the LSTM model\n",
    "def create_dataset(data, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(data)-look_back-1):\n",
    "        X.append(data[i:(i+look_back), 0])\n",
    "        Y.append(data[i + look_back, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "# Create input-output pairs for the LSTM model\n",
    "look_back = 1\n",
    "X_train, y_train = create_dataset(train, look_back)\n",
    "X_test, y_test = create_dataset(test, look_back)\n",
    "\n",
    "# Reshape the data into [samples, time steps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Fit the LSTM model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "lstm_model.add(Dense(1))\n",
    "lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "lstm_model.fit(X_train, y_train, epochs=100, batch_size=1)\n",
    "\n",
    "# Make predictions using the LSTM model\n",
    "lstm_predictions = lstm_model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error of the LSTM model\n",
    "lstm_mse = mean_squared_error(y_test, lstm_predictions)\n",
    "print(f'LSTM MSE: {lstm_mse}')\n",
    "\n",
    "# Compare the performance of the two models\n",
    "if prophet_mse < lstm_mse:\n",
    "    print('Prophet performs better')\n",
    "else:\n",
    "    print('LSTM performs better')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "4598/4598 [==============================] - 14s 2ms/step - loss: 0.0046\n",
      "Epoch 2/100\n",
      "4598/4598 [==============================] - 12s 3ms/step - loss: 0.0019\n",
      "Epoch 3/100\n",
      "4598/4598 [==============================] - 13s 3ms/step - loss: 0.0019\n",
      "Epoch 4/100\n",
      "4598/4598 [==============================] - 14s 3ms/step - loss: 0.0019\n",
      "Epoch 5/100\n",
      "4598/4598 [==============================] - 13s 3ms/step - loss: 0.0019\n",
      "Epoch 6/100\n",
      "4598/4598 [==============================] - 13s 3ms/step - loss: 0.0019\n",
      "Epoch 7/100\n",
      "4598/4598 [==============================] - 12s 3ms/step - loss: 0.0019\n",
      "Epoch 8/100\n",
      " 415/4598 [=>............................] - ETA: 10s - loss: 0.0021"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# from fbprophet import Prophet\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\"\"\"# Load the data\n",
    "data = pd.read_csv('data.csv', parse_dates=['Date'], index_col='Date')\n",
    "\n",
    "\n",
    "# Prepare the data for Prophet\n",
    "prophet_data = data.reset_index()\n",
    "prophet_data.columns = ['ds', 'y']\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_size = int(len(data) * 0.8)\n",
    "train, test = prophet_data[0:train_size], prophet_data[train_size:len(prophet_data)]\n",
    "\n",
    "# Fit the Prophet model\n",
    "prophet_model = Prophet()\n",
    "prophet_model.fit(train)\n",
    "\n",
    "# Make predictions using the Prophet model\n",
    "prophet_forecast = prophet_model.predict(test[['ds']])\n",
    "prophet_predictions = prophet_forecast['yhat'].values\n",
    "\n",
    "# Calculate the mean squared error of the Prophet model\n",
    "prophet_mse = mean_squared_error(test['y'], prophet_predictions)\n",
    "print(f'Prophet MSE: {prophet_mse}')\"\"\"\n",
    "\n",
    "data = data[['Price']]\n",
    "# Prepare the data for LSTM\n",
    "lstm_data = data.values\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train, test = lstm_data[0:train_size], lstm_data[train_size:len(lstm_data)]\n",
    "\n",
    "# Define a function to create input-output pairs for the LSTM model\n",
    "def create_dataset(data, look_back=1):\n",
    "    X, Y = [], []\n",
    "    for i in range(len(data)-look_back-1):\n",
    "        X.append(data[i:(i+look_back), 0])\n",
    "        Y.append(data[i + look_back, 0])\n",
    "    return np.array(X), np.array(Y)\n",
    "\n",
    "# Create input-output pairs for the LSTM model\n",
    "look_back = 1\n",
    "X_train, y_train = create_dataset(train, look_back)\n",
    "X_test, y_test = create_dataset(test, look_back)\n",
    "\n",
    "# Reshape the data into [samples, time steps, features]\n",
    "X_train = np.reshape(X_train, (X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = np.reshape(X_test, (X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Fit the LSTM model\n",
    "lstm_model = Sequential()\n",
    "lstm_model.add(LSTM(4, input_shape=(1, look_back)))\n",
    "lstm_model.add(Dense(1))\n",
    "lstm_model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "lstm_model.fit(X_train, y_train, epochs=100, batch_size=1)\n",
    "\n",
    "# Make predictions using the LSTM model\n",
    "lstm_predictions = lstm_model.predict(X_test)\n",
    "\n",
    "# Calculate the mean squared error of the LSTM model\n",
    "lstm_mse = mean_squared_error(y_test, lstm_predictions)\n",
    "print(f'LSTM MSE: {lstm_mse}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
