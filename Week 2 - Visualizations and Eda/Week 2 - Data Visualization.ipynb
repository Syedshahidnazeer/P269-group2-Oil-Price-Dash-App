{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data set using pandas\n",
    "data=pd.read_csv('E:\\Excelr-P269-Internship-Project-Group2-OIl-Price-Prediction-And-Forecasting-Using-Python\\oil_prices_yahoo1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# covertnig the date column to datetime using pandas\n",
    "data['Date'] = pd.to_datetime(data['Date'], errors='coerce')\n",
    "\n",
    "# creating a data frame using pandas\n",
    "df=pd.DataFrame(data)\n",
    "\n",
    "# renaming the column to price\n",
    "df.rename(columns = {'Close':'Price'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date      Price\n",
      "0 2000-08-23  32.049999\n",
      "1 2000-08-24  31.629999\n",
      "2 2000-08-25  32.049999\n",
      "3 2000-08-28  32.869999\n",
      "4 2000-08-29  32.720001\n",
      "           Date      Price\n",
      "5746 2023-07-17  74.150002\n",
      "5747 2023-07-18  75.750000\n",
      "5748 2023-07-19  75.349998\n",
      "5749 2023-07-20  75.629997\n",
      "5750 2023-07-21  77.070000\n"
     ]
    }
   ],
   "source": [
    "print(df.head())\n",
    "print(df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5751 entries, 0 to 5750\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype         \n",
      "---  ------  --------------  -----         \n",
      " 0   Date    5751 non-null   datetime64[ns]\n",
      " 1   Price   5751 non-null   float64       \n",
      "dtypes: datetime64[ns](1), float64(1)\n",
      "memory usage: 90.0 KB\n"
     ]
    }
   ],
   "source": [
    "# info function gives us the raw information of data such as any null values, data types e.t.c.\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5751, 2)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Date     0\n",
       "Price    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking for the null values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary Statistics:\n",
      "Mean: 63.85376977713248\n",
      "Median: 61.540000915527344\n",
      "Minimum: -37.630001068115234\n",
      "Maximum: 145.2899932861328\n",
      "Standard Deviation: 25.586500058183233\n",
      "\n",
      "Dickey-Fuller Test Results:\n",
      "ADF Statistic: -2.696203550982578\n",
      "p-value: 0.07469752769722504\n",
      "1%: -3.431493547724062\n",
      "5%: -2.862045338455472\n",
      "10%: -2.567038989861576\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def summarize_time_series(data):\n",
    "    # Calculate summary statistics\n",
    "    mean = np.mean(data)\n",
    "    median = np.median(data)\n",
    "    min_value = np.min(data)\n",
    "    max_value = np.max(data)\n",
    "    std_dev = np.std(data)\n",
    "\n",
    "    # Perform Dickey-Fuller test to check for stationarity\n",
    "    result = adfuller(data)\n",
    "    adf_stat = result[0]\n",
    "    p_value = result[1]\n",
    "    critical_values = result[4]\n",
    "\n",
    "    # Print summary statistics\n",
    "    print('Summary Statistics:')\n",
    "    print('Mean: {}'.format(mean))\n",
    "    print('Median: {}'.format(median))\n",
    "    print('Minimum: {}'.format(min_value))\n",
    "    print('Maximum: {}'.format(max_value))\n",
    "    print('Standard Deviation: {}'.format(std_dev))\n",
    "\n",
    "    # Print Dickey-Fuller test results\n",
    "    print('\\nDickey-Fuller Test Results:')\n",
    "    print('ADF Statistic: {}'.format(adf_stat))\n",
    "    print('p-value: {}'.format(p_value))\n",
    "    for key, value in critical_values.items():\n",
    "        print('{}: {}'.format(key, value))\n",
    "\n",
    "# Example usage\n",
    "summarize_time_series(df['Price'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the ADF (\"Augmented Dickey-Fuller\") statistic is -2.696204 and the p-value is 0.074698. The critical values for the test at the 1%, 5%, and 10% significance levels are -3.431, -2.862, and -2.567, respectively. This means that if the ADF statistic is less than (more negative than) the critical value at a given significance level, we can reject the null hypothesis and conclude that the time series is stationary at that significance level."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "In addition to statistical tests, you can also visually examine the time series data to check for stationarity. One way to do this is by plotting the time series and looking for trends or seasonality2. You can also split the time series into different partitions and compare the statistical properties of each partition2. If the mean, variance, and other statistical properties are stable across time, this suggests that the time series may be stationary.\n",
    "\n",
    "Itâ€™s important to note that stationarity is an assumption of many time series forecasting models, so itâ€™s important to determine if your data is stationary before building a model. If your data is non-stationary, you may need to transform it (e.g., by differencing or detrending) to make it stationary before building a model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the output you provided, the mean value of your time series data is **63.85**, the median is **61.54**, the minimum value is **-37.63**, and the maximum value is **145.29**. The standard deviation is **25.59**, which indicates that the data has a moderate amount of variability.\n",
    "\n",
    "The Dickey-Fuller test results show an ADF statistic of **-2.70** and a p-value of **0.07**. The p-value is greater than the commonly used significance level of 0.05, which suggests that we cannot reject the null hypothesis that the time series has a unit root (i.e., it is non-stationary). However, the p-value is relatively close to 0.05, so you may want to perform additional tests or examine the data visually to determine if it is stationary or not.\n",
    "\n",
    "The critical values for the test at the 1%, 5%, and 10% levels are **-3.43**, **-2.86**, and **-2.57**, respectively. Since the ADF statistic is greater than all of these critical values, this also suggests that we cannot reject the null hypothesis of non-stationarity.\n",
    "\n",
    "Is there anything else you would like to know? ðŸ˜Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KPSS Test Results:\n",
      "KPSS Statistic: 2.3890250979796517\n",
      "p-value: 0.01\n",
      "10%: 0.347\n",
      "5%: 0.463\n",
      "2.5%: 0.574\n",
      "1%: 0.739\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import kpss\n",
    "\n",
    "def kpss_test(data):\n",
    "    # Perform KPSS test\n",
    "    result = kpss(data)\n",
    "    kpss_stat = result[0]\n",
    "    p_value = result[1]\n",
    "    critical_values = result[3]\n",
    "\n",
    "    # Print KPSS test results\n",
    "    print('KPSS Test Results:')\n",
    "    print('KPSS Statistic: {}'.format(kpss_stat))\n",
    "    print('p-value: {}'.format(p_value))\n",
    "    for key, value in critical_values.items():\n",
    "        print('{}: {}'.format(key, value))\n",
    "\n",
    "# Example usage\n",
    "kpss_test(df['Price'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the output you provided, the KPSS statistic for your time series data is **2.39** and the p-value is **0.01**. Since the p-value is less than the commonly used significance level of 0.05, this suggests that we can reject the null hypothesis that the time series is trend-stationary. This means that your time series data may have a unit root and be non-stationary.\n",
    "\n",
    "The critical values for the test at the 10%, 5%, 2.5%, and 1% levels are **0.347**, **0.463**, **0.574**, and **0.739**, respectively. Since the KPSS statistic is greater than all of these critical values, this also suggests that we can reject the null hypothesis of trend-stationarity.\n",
    "\n",
    "If your time series data is non-stationary, you may need to transform it (e.g., by differencing or detrending) to make it stationary before building a forecasting model. There are several methods for transforming non-stationary data, and the appropriate method will depend on the characteristics of your data.\n",
    "\n",
    "Is there anything else you would like to know? ðŸ˜Š"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "First Difference:\n",
      "Dickey-Fuller Test Results:\n",
      "ADF Statistic: -12.47495528713085\n",
      "p-value: 3.183489760467687e-23\n",
      "1%: -3.431493547724062\n",
      "5%: -2.862045338455472\n",
      "10%: -2.567038989861576\n",
      "\n",
      "Detrended Data:\n",
      "Dickey-Fuller Test Results:\n",
      "ADF Statistic: -9.906011501169225\n",
      "p-value: 3.262152993179196e-17\n",
      "1%: -3.431496756314084\n",
      "5%: -2.862046756071205\n",
      "10%: -2.5670397445004576\n",
      "\n",
      "Logarithm of Data:\n",
      "Dickey-Fuller Test Results:\n",
      "ADF Statistic: -2.541675506706014\n",
      "p-value: 0.10566061922346581\n",
      "1%: -3.431492349126996\n",
      "5%: -2.862044808892236\n",
      "10%: -2.567038707959433\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "\n",
    "def test_stationarity(data):\n",
    "    # Perform Dickey-Fuller test\n",
    "    result = adfuller(data)\n",
    "    adf_stat = result[0]\n",
    "    p_value = result[1]\n",
    "    critical_values = result[4]\n",
    "\n",
    "    # Print Dickey-Fuller test results\n",
    "    print('Dickey-Fuller Test Results:')\n",
    "    print('ADF Statistic: {}'.format(adf_stat))\n",
    "    print('p-value: {}'.format(p_value))\n",
    "    for key, value in critical_values.items():\n",
    "        print('{}: {}'.format(key, value))\n",
    "\n",
    "def make_stationary(data):\n",
    "    # Calculate first difference\n",
    "    diff = data.diff().dropna()\n",
    "\n",
    "    # Test for stationarity\n",
    "    print('\\nFirst Difference:')\n",
    "    test_stationarity(diff)\n",
    "\n",
    "    # Detrend data\n",
    "    detrended = data - data.rolling(window=12).mean()\n",
    "    detrended = detrended.dropna()\n",
    "\n",
    "    # Test for stationarity\n",
    "    print('\\nDetrended Data:')\n",
    "    test_stationarity(detrended)\n",
    "\n",
    "    # Take logarithm of data\n",
    "    log_data = np.log(data)\n",
    "    log_data = log_data.dropna()\n",
    "\n",
    "    # Test for stationarity\n",
    "    print('\\nLogarithm of Data:')\n",
    "    test_stationarity(log_data)\n",
    "\n",
    "# Example usage\n",
    "make_stationary(df['Price'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
